<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Communication-Efficient Learning of Deep Networks from Decentralized Data | Fallenk&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="title: 基于分散数据的深度网络通信高效学习">
<meta name="keywords" content="论文阅读">
<meta property="og:type" content="article">
<meta property="og:title" content="Communication-Efficient Learning of Deep Networks from Decentralized Data">
<meta property="og:url" content="https://fallenk.github.io/2019/01/05/Communication-Efficient-Learning-of-Deep-Networks-from-Decentralized-Data/index.html">
<meta property="og:site_name" content="Fallenk&#39;s Blog">
<meta property="og:description" content="title: 基于分散数据的深度网络通信高效学习">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://fallenk.github.io/2019/01/05/Communication-Efficient-Learning-of-Deep-Networks-from-Decentralized-Data/demo1.png">
<meta property="og:image" content="https://fallenk.github.io/2019/01/05/Communication-Efficient-Learning-of-Deep-Networks-from-Decentralized-Data/demo2.png">
<meta property="og:updated_time" content="2019-01-12T18:12:36.216Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Communication-Efficient Learning of Deep Networks from Decentralized Data">
<meta name="twitter:description" content="title: 基于分散数据的深度网络通信高效学习">
<meta name="twitter:image" content="https://fallenk.github.io/2019/01/05/Communication-Efficient-Learning-of-Deep-Networks-from-Decentralized-Data/demo1.png">
  
    <link rel="alternate" href="/atom.xml" title="Fallenk&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    
    <div id="header-inner" class="inner">
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://fallenk.github.io"></form>
      </div>
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">首页</a>
        
          <a class="main-nav-link" href="/archives">归档</a>
        
          <a class="main-nav-link" href="/about">关于</a>
        
      </nav>
      
    </div>
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Fallenk&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">经历，心得，笔记，目标</a>
        </h2>
      
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Communication-Efficient-Learning-of-Deep-Networks-from-Decentralized-Data" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/01/05/Communication-Efficient-Learning-of-Deep-Networks-from-Decentralized-Data/" class="article-date">
  <time datetime="2019-01-05T14:13:38.000Z" itemprop="datePublished">2019-01-05</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/论文阅读/">论文阅读</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Communication-Efficient Learning of Deep Networks from Decentralized Data
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <blockquote>
<p>title: 基于分散数据的深度网络通信高效学习</p>
</blockquote>
<a id="more"></a>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>现代移动设备可以访问适合学习模型的大量数据，这反过来可以极大地改善设备上的用户体验。例如，语言模型可以改善语音识别和文本输入，图像模型可以自动选择好照片。然而，这种丰富的数据通常是隐私敏感的，数量大或两者兼而有之，这可能妨碍使用传统方法记录到数据中心并在那里进行训练。我们提倡一种替代方案，即将<strong>训练数据分布在移动设备上，并学习共享模型是通过聚合本地计算的更新模型得到</strong>。我们将这种分散的方法称为联合学习。</p>
<p>我们提出了一种<strong>基于迭代模型平均的联合学习</strong>深度网络的实用方法，并进行了广泛的经验评估，考虑了五种不同的模型结构和四种数据集。这些实验证明该方法对于<strong>非平衡和非IID数据分布</strong>是稳健的，这是该设置的一个定义特征。<strong>通信成本</strong>是主要的约束条件，与同步随机梯度下降相比，我们显示所需通信轮次减少了10-100倍。</p>
<h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h1><p>手机和平板电脑越来越多地成为许多人的主要计算设备[30,2]。 这些设备上的强大传感器（包括摄像头，麦克风和GPS），加上它们经常携带的事实，意味着它们可以访问前所未有的大量数据，其中大部分是私有的。<br>在这些数据上学到的模型有望通过为更智能的应用程序提供动力来大大提高可用性，但<strong>数据的敏感性意味着将其存储在集中位置存在风险和责任</strong>。</p>
<p>我们研究了一种学习技术，该技术允许用户集体获得从这些丰富数据训练的共享模型的好处，而无需集中存储它。我们称之为联合学习，因为学习任务是由一个由中央服务器(server)协调的参与设备（我们称之为客户端client）的松散联合解决的。</p>
<p>每个客户端都有一个从未上传到服务器的<strong>本地训练数据集</strong>。相反，<strong>每个客户端计算服务器维护的当前全局模型的更新，并且仅传递此更新</strong>。 这是2012年白宫关于消费者数据隐私的报告[39]提出的重点收集或数据最小化原则的直接应用。由于这些更新特定于改进当前模型，因此一旦应用它们就没有理由存储它们。</p>
<p>这种方法的主要优点是<strong>模型训练</strong>与<strong>直接访问原始训练数据</strong>的需要脱钩。显然，仍然需要一些信任的服务器协调训练。但是，对于可以根据每个客户端上可用数据指定训练目标的应用程序，联合学习可以通过将攻击面限制为仅设备而非设备和云来显着降低隐私和安全风险。</p>
<p>我们的主要贡献：</p>
<ol>
<li>确定移动设备分散数据训练问题是一个重要的研究方向;</li>
<li>选择可应用于此设置的简单实用的算法;</li>
<li>对一些方法进行广泛的实证评估。</li>
</ol>
<p>更具体地说，我们引入了<strong>FederatedAveraging</strong>算法，<strong>该算法将每个客户端上的本地随机梯度下降（SGD）与服务器用来执行模型平均。</strong>我们对该算法进行了广泛的实验，证明它对非平衡和非IID数据分布具有鲁棒性，并且可以减少在分散数据上训练深度网络所需的通信量。</p>
<h2 id="Federated-Learning"><a href="#Federated-Learning" class="headerlink" title="Federated Learning"></a>Federated Learning</h2><p>联合学习的理想问题具有以下特性：<br>1）对来自移动设备的真实数据的训练提供了优于数据中心通常可用的代理数据培训的明显优势。<br>2）该数据对隐私敏感或规模大（与模型的大小相比），因此最好不要仅仅为了模型训练（使用聚焦​​收集原则）而将其记录到数据中心。<br>3）对于监督任务，可以从用户交互中自然地推断出数据上的标签。</p>
<p>许多支持移动设备智能行为的模型符合上述标准。作为两个例子，我们考虑图像分类，例如预测哪些照片最有可能在未来多次被观看或共享;和语言模型，可以通过改进解码，下一个单词预测，甚至预测整个回复来改善触摸屏键盘上的语音识别和文本输入[10]。这些任务的潜在训练数据（用户拍摄的所有照片以及他们在移动键盘上键入的所有内容，包括密码，URL，消息等）都可能对隐私敏感。绘制这些示例的分布也可能与容易获得的代理数据集大不相同：聊天和文本消息中的语言使用通常与标准语言语料库（例如，维基百科和其他Web文档）大不相同;人们拍摄手机的照片可能与典型的Flickr照片完全不同。最后，这些问题的标签可以直接使用：输入的文本是自我标记的，用于学习语言模型，照片标签可以通过自然用户与照片应用程序的交互来定义（照片被删除，共享或查看）。</p>
<p>这两项任务都非常适合学习神经网络。对于图像分类，前馈深度网络，特别是卷积网络，众所周知提供最先进的结果[26,25]。对于语言建模任务，递归神经网络，特别是LSTM，已经取得了最先进的结果[20,5,22]。</p>
<h2 id="Privacy？？"><a href="#Privacy？？" class="headerlink" title="Privacy？？"></a>Privacy？？</h2><p>与持久数据的数据中心训练相比，联合学习具有明显的隐私优势。持有“匿名”数据集仍然可以通过与其他数据的连接将用户隐私置于风险之中[37]。相反，为联合学习传输的信息是改进特定模型所必需的最小更新（当然，隐私利益的强度取决于更新的内容）更新本身可以（并且应该）是短暂的。它们永远不会包含比原始训练数据更多的信息（通过数据处理不等式），并且通常包含的内容要少得多。此外，聚合算法不需要更新源，因此可以在不通过诸如Tor [7]的混合网络或通过可信第三方识别元数据的情况下发送更新。我们将在本文末尾简要讨论将<strong>联合学习与安全多方计算和差异隐私相结合</strong>的可能性。</p>
<h2 id="Federated-Optimization"><a href="#Federated-Optimization" class="headerlink" title="Federated Optimization"></a>Federated Optimization</h2><p>我们将联合学习中<strong>隐含的优化问题称为联合优化</strong>，将连接（和对比）绘制为分布式优化。联合优化具有几个关键属性，可将其与典型的分布式优化问题区分开来：</p>
<ul>
<li><strong>Non-IID</strong> 给定客户端上的训练数据通常基于特定用户对移动设备的使用，因此任何特定用户的本地数据集将不代表真实分布。</li>
<li><strong>Unbalanced</strong> 同样，一些用户将比其他用户更多地使用服务或应用程序，从而导致不同数量的本地培训数据。</li>
<li><strong>Massively distributed</strong> 我们希望参与优化的客户端数量远远大于每个客户端的平均示例数量。</li>
<li><strong>Limited communication</strong>移动设备经常处于脱机状态或连接缓慢或昂贵。</li>
</ul>
<p>这项工作中，我们的<strong>重点是优化</strong>的<strong>非IID和不平衡属性</strong>，以及<strong>通信约束的关键性质</strong>。部署的联合优化系统还必须解决许多实际问题：随着数据的添加和删除而变化的客户端数据集;客户可用性与复杂方式的本地数据分布相关（例如，美国英语使用者的电话可能会在不同时间插入英国英语的发言者）;客户端不响应或发送损坏更新。</p>
<p>这些问题超出了目前的工作范围;相反，我们使用适合实验的受控环境，但仍解<strong>决客户端可用性</strong>以及<strong>不平衡</strong>和<strong>非IID数据</strong>的关键问题。我们假设<strong>一个同步更新方案，进行多轮通信。有一组固定的$K$客户端，每个客户端都有一个固定的本地数据集。在每轮的开始，随机选择部分$C$个客户端，并且服务器将当前全局算法状态发送到这些客户端中的每一个（例如，当前模型参数）</strong>。我们只选择一小部分客户来提高效率，因为我们的实验显示，在超过某一点时添加更多客户的收益递减。然后，<strong>每个选定的客户端基于全局状态及其本地数据集执行本地计算，并向服务器发送更新。然后，服务器将这些更新应用于其全局状态，并重复该过程。</strong></p>
<p>虽然我们关注非凸神经网络目标，但我们考虑的算法适用于任何有限目标的式子：</p>
<p>$\min _ { w \in \mathbb { R } ^ { d } } f ( w ) \quad \text { where } \quad f ( w ) \stackrel { \text { def } } { = } \frac { 1 } { n } \sum _ { i = 1 } ^ { n } f _ { i } ( w )$         （1）</p>
<p>对于机器学习问题，我们把 $f _ { i } ( w ) =\ell \left( x _ { i } , y _ { i } ; w \right) $ 由 损失函数 和模型参数 $w$ 组成。</p>
<p>我们假设数据被分区有$K$个客户端上，$p_{k}$是客户端$k$上的数据点索引集合, $n _ { k } = \left| \mathcal { p } _ { k } \right|$.大小<br>因此我们重写式子(1)为:<br>$f ( w ) = \sum _ { k = 1 } ^ { K } \frac { n _ { k } } { n } F _ { k } ( w ) \quad$ where $\quad F _ { k } ( w ) = \frac { 1 } { n _ { k } } \sum _ { i \in \mathcal { P } _ { k } } f _ { i } ( w )$</p>
<p>？？总数据集大小是n；左边是式子是说<code>1..K</code>个客户端训练数据，客户端K的数据集是$n _ { k }$, 加权平均$F _ { k } ( w )$; 同时右边是的式子是指每一个$F _ { k } ( w )$有平均梯度</p>
<p>如果通过在客户端上随机均匀地分布训练样例来形成分区$p_{k}$；然后我们将会有 <img src="/2019/01/05/Communication-Efficient-Learning-of-Deep-Networks-from-Decentralized-Data/demo1.png" alt="">;就是client k的期望。这是通常由分布式优化算法做出的IID假设;我们指的是这不成立的情况($F _ { k }$坏的分布预测)</p>
<p>在数据中心优化中，<strong>通信成本</strong>相对较小，计算成本占主导地位，最近的重点主要是使用GPU降低这些成本。相反，在联合优化中，通信成本占主导地位-我们通常会受到1MB/s或更低的上传带宽的限制。此外，客户通常只会在充电，插入和未计量的Wi-Fi连接时自愿参与优化。此外，我们希望每个客户每天只参加少量的更新轮次。另一方面，由于任何单个设备上的数据集与总数据集大小相比较小，并且现代智能手机具有相对较快的处理器（包括GPU），与许多模型类型的通信成本相比，计算变得基本上是免费的。</p>
<p>因此，我们的目标是<strong>使用额外的计算</strong>，<strong>以减少训练模型所需的通信轮次数</strong>。我们可以通过两种主要方式添加计算：<br>1）增加并行性，我们使用<strong>更多客户端独立工作</strong>在每个通信轮次之间<br>2）<strong>增加每个客户端的计算</strong>，而不是像梯度计算那样执行简单的计算，每个客户端在每个通信轮次之间执行更复杂的计算。<br>我们研究了这两种方法，但是<strong>我们实现的加速主要是因为在每个客户端上添加更多计算</strong>；一旦在客户端上使用最低级别的并行性。</p>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><p>McDonald等人已经研究了通过迭代平均局部训练的模型进行的分布式训练[28]感知器和Povey[31]用于语音识别DNN。张[42]研究了一种采用“软”平均的异步方法“soft” averaging。这些工作仅考虑群集/数据中心设置（最多16个workers，基于快速网络的挂钟时间），并且不考虑非平衡和非IID的数据集，这些属性对联合学习设置至关重要。我们将这种<strong>算法类型调整为联合设置并执行适当的实证评估</strong>，这些评估会提出与数据中心设置相关的不同问题，并且需要不同的方法。</p>
<p>使用与我们相似的动机，Neverova等。 [29]还讨论了在设备上保留敏感用户数据的优势。 Shokri和Shmatikov [35]的工作在几个方面有关：<strong>他们专注于训练深层网络，强调隐私的重要性，并通过在每轮通信中共享一部分参数来解决通信成本</strong>;然而，他们也不考虑<strong>不平衡和非IID数据</strong>，并且实证评估是有限的。</p>
<p>在凸设置中，分布式优化和估计问题已经引起了人们的重视[4,15,33]，并且一些算法确实专注于通信效率[45,34,40,27,43]。除了假设凸性之外，这个现有工作通常要求客户端的数量远小于每个客户端的示例数量，数据以IID方式分布在客户端上，并且每个节点具有相同的数量数据点 - <strong>联合优化设置中违反了所有这些假设</strong>。异步分布式SGD也已应用于训练神经网络，例如Dean等人。 [12]，但这些方法在联合设置中需要大量的更新。分布式一致性算法（例如，[41]）放宽了IID假设，但对于很多客户端的通信约束优化仍然不是很好。</p>
<p>我们考虑是单次的简单的平均对参数化的算法家族来说，其中每一个client解决model的最小损失在本地数据上，这些模型将会被平均分配到最终模型上。在IID数据的凸案例中已经广泛研究了这种方法，并且众所周知，在最坏的情况下，<strong>生成的全局模型几乎等于单个客户端上训练模型的训练效果。</strong></p>
<h1 id="2-The-FederatedAveraging-Algorithm"><a href="#2-The-FederatedAveraging-Algorithm" class="headerlink" title="2 The FederatedAveraging Algorithm"></a>2 The FederatedAveraging Algorithm</h1><p>最近深度学习的众多成功应用几乎完全依赖于随机梯度下降（SGD）的变体进行优化;事实上，许多进步可以被理解为<strong>通过使用简单的基于梯度的方法使模型的结构（以及因此损失函数）更适合于优化</strong>。因此，我们很自然地<strong>从SGD开始构建用于联合优化的算法</strong>。SGD可以自然地应用于联合优化问题，其中每轮通信完成一个batch数量梯度计算（例如在随机选择的客户端上）。这种方法计算效率很高，但需要大量的训练才能生成出良好的模型(即使使用像批量标准化这样的高级方法，Ioffe和Szegedy也会在尺寸为60的minibatches上训练MNIST 50000步).我们在CIFAR-10实验中考虑了这个基线。</p>
<p>在联合设置中，涉及更多客户端的挂钟时间成本很低，因此对于我们的基线，我们<strong>使用大批量同步SGD</strong>;experiments by Chen et al.表明这种方法在数据中心设置中是最先进的，它在性能上优于异步方法。为了要在联合设置中应用此方法，我们在每一轮中选择一小部分$C$客户，并计算这些客户持有的所有数据的损失梯度。因此，$C$部分控制着global batch size的大小，C=1对应于全批（非随机）梯度下降。我们将此基线算法称为FederatedSGD（或FedSGD）。FedSGD的典型实现：C=1, 一个固定的学习率η每个client k计算$g <em>{k} = \nabla F (w</em>{t})$;当前模型的本地数据的平均梯度$w_{t}$;每个中心服务器聚合这些梯度并且引用这些更新<img src="/2019/01/05/Communication-Efficient-Learning-of-Deep-Networks-from-Decentralized-Data/demo2.png" alt=""></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://fallenk.github.io/2019/01/05/Communication-Efficient-Learning-of-Deep-Networks-from-Decentralized-Data/" data-id="cjqumxe8m0003kr8ovtdorys8" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/论文阅读/">论文阅读</a></li></ul>

    </footer>
  </div>
  
    
 <script src="/jquery/jquery.min.js"></script>
  <div id="random_posts">
    <h2>推荐文章</h2>
    <div class="random_posts_ul">
      <script>
          var random_count =4
          var site = {BASE_URI:'/'};
          function load_random_posts(obj) {
              var arr=site.posts;
              if (!obj) return;
              // var count = $(obj).attr('data-count') || 6;
              for (var i, tmp, n = arr.length; n; i = Math.floor(Math.random() * n), tmp = arr[--n], arr[n] = arr[i], arr[i] = tmp);
              arr = arr.slice(0, random_count);
              var html = '<ul>';
            
              for(var j=0;j<arr.length;j++){
                var item=arr[j];
                html += '<li><strong>' + 
                item.date + ':&nbsp;&nbsp;<a href="' + (site.BASE_URI+item.uri) + '">' + 
                (item.title || item.uri) + '</a></strong>';
                if(item.excerpt){
                  html +='<div class="post-excerpt">'+item.excerpt+'</div>';
                }
                html +='</li>';
                
              }
              $(obj).html(html + '</ul>');
          }
          $('.random_posts_ul').each(function () {
              var c = this;
              if (!site.posts || !site.posts.length){
                  $.getJSON(site.BASE_URI + 'js/posts.js',function(json){site.posts = json;load_random_posts(c)});
              } 
               else{
                load_random_posts(c);
              }
          });
      </script>
    </div>
  </div>

    
<nav id="article-nav">
  
    <a href="/2019/01/06/三维动画与交互技术复习/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">上一篇</strong>
      <div class="article-nav-title">
        
          三维动画与交互技术复习
        
      </div>
    </a>
  
  
    <a href="/2019/01/05/FEDERATED-LEARNING-STRATEGIES-FOR-IMPROVING-COMMUNICATION-EFFICIENCY/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">下一篇</strong>
      <div class="article-nav-title">FEDERATED LEARNING: STRATEGIES FOR IMPROVING COMMUNICATION EFFICIENCY</div>
    </a>
  
</nav>

  
</article>
 
     
  <div class="comments" id="comments">
    
     
       
      <div id="cloud-tie-wrapper" class="cloud-tie-wrapper"></div>
    
       
      
      
  </div>
 
  

</section>
           
    <aside id="sidebar">
  
    

  
    
    <div class="widget-wrap">
    
      <div class="widget" id="toc-widget-fixed">
      
        <strong class="toc-title">文章目录</strong>
        <div class="toc-widget-list">
              <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Abstract"><span class="toc-number">1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-Introduction"><span class="toc-number">2.</span> <span class="toc-text">1 Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Federated-Learning"><span class="toc-number">2.1.</span> <span class="toc-text">Federated Learning</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Privacy？？"><span class="toc-number">2.2.</span> <span class="toc-text">Privacy？？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Federated-Optimization"><span class="toc-number">2.3.</span> <span class="toc-text">Federated Optimization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Related-Work"><span class="toc-number">2.4.</span> <span class="toc-text">Related Work</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-The-FederatedAveraging-Algorithm"><span class="toc-number">3.</span> <span class="toc-text">2 The FederatedAveraging Algorithm</span></a></li></ol>
          </div>
      </div>
    </div>

  
    

  
    
  
    
  
    

  
    
  
    <!--微信公众号二维码-->


  
</aside>

      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-left">
      &copy; 2014 - 2019 Fallenk Liu&nbsp;|&nbsp;
      主题 <a href="https://github.com/giscafer/hexo-theme-cafe/" target="_blank">Cafe</a>
    </div>
     <div id="footer-right">
      联系方式&nbsp;|&nbsp;fallenk_liu@yeah.com
    </div>
  </div>
</footer>
 <script src="/jquery/jquery.min.js"></script>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">首页</a>
  
    <a href="/archives" class="mobile-nav-link">归档</a>
  
    <a href="/about" class="mobile-nav-link">关于</a>
  
</nav>
    <img class="back-to-top-btn" src="/images/fly-to-top.png"/>
<script>
// Elevator script included on the page, already.
window.onload = function() {
  var elevator = new Elevator({
    selector:'.back-to-top-btn',
    element: document.querySelector('.back-to-top-btn'),
    duration: 1000 // milliseconds
  });
}
</script>
      

  
    <script>
      var cloudTieConfig = {
        url: document.location.href, 
        sourceId: "",
        productKey: "e2fb4051c49842688ce669e634bc983f",
        target: "cloud-tie-wrapper"
      };
    </script>
    <script src="https://img1.ws.126.net/f2e/tie/yun/sdk/loader.js"></script>
    

  







<!-- author:forvoid begin -->
<!-- author:forvoid begin -->

<!-- author:forvoid end -->

<!-- author:forvoid end -->


  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      })
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      })
    </script>
    <script type="text/javascript" src="https://cdn.rawgit.com/mathjax/MathJax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


 <script src="/js/is.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>
<script src="/js/elevator.js"></script>
  </div>
</body>
</html>